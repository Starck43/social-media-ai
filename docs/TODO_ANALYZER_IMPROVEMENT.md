# TODO: –£–ª—É—á—à–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ AIAnalyzerV2

## üéØ –¶–µ–ª—å

–ò–∑–º–µ–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –≤–∏–¥–µ–æ) –¥–ª—è:
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –º–µ–¥–∏–∞
- –≠–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ (~70%)
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

## ‚ùå –¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞

**–§–∞–π–ª:** `app/services/ai/analyzer_v2.py`

**–¢–µ–∫—É—â–∞—è –ª–æ–≥–∏–∫–∞ (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–ê–Ø):**

```python
async def analyze_content(self, content, source):
    classified = ContentClassifier.classify_content(content)
    
    # 1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –û–¢–î–ï–õ–¨–ù–û
    text_result = await self._analyze_text(classified['text'])
    # DeepSeek: "Positive sentiment"
    
    # 2. –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –û–¢–î–ï–õ–¨–ù–û
    image_result = await self._analyze_images(classified['images'])
    # GPT-4V: "Logo on image, happy people"
    
    # 3. –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –û–¢–î–ï–õ–¨–ù–û
    video_result = await self._analyze_videos(classified['videos'])
    # GPT-4V: "Product demonstration video"
    
    # 4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∫–æ–Ω—Ü–µ
    unified = self._create_unified_summary(text_result, image_result, video_result)
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ—Ä—è–µ—Ç—Å—è (—Ç–µ–∫—Å—Ç –∏ –º–µ–¥–∏–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ)
- ‚ùå –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ (3 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM)
- ‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
- ‚ùå –î–æ—Ä–æ–≥–æ (–æ–ø–ª–∞—Ç–∞ –∑–∞ 3 –∑–∞–ø—Ä–æ—Å–∞)

**–ü—Ä–∏–º–µ—Ä:**
```
–ü–æ—Å—Ç: "–í—Å—Ç—Ä–µ—á–∞–π—Ç–µ –Ω–∞—à—É –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é!" + –§–æ—Ç–æ —Å –ª–æ–≥–æ—Ç–∏–ø–æ–º

–¢–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑:
  - –¢–µ–∫—Å—Ç: "Positive sentiment" (–±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ñ–æ—Ç–æ)
  - –§–æ—Ç–æ: "Brand logo visible" (–±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ç–µ–∫—Å—Ç–∞)
  
–ü—Ä–æ–±–ª–µ–º–∞: –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç —á—Ç–æ —Ñ–æ—Ç–æ –û–¢–ù–û–°–ò–¢–°–Ø –∫ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
```

## ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ (TO IMPLEMENT)

**–ö–æ–Ω—Ü–µ–ø—Ü–∏—è: Vision ‚Üí Text ‚Üí Analyze**

### –®–∞–≥ 1: Vision –º–æ–¥–µ–ª—å –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¢–ï–ö–°–¢

```python
vision_descriptions = []

# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–≤–∏–¥–µ–æ
for media in images + videos:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Vision –º–æ–¥–µ–ª—å –¢–û–õ–¨–ö–û –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
    prompt = "–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ/–≤–∏–¥–µ–æ. –£–∫–∞–∂–∏: –æ–±—ä–µ–∫—Ç—ã, –ª—é–¥–µ–π, —Ç–µ–∫—Å—Ç, —ç–º–æ—Ü–∏–∏, –±—Ä–µ–Ω–¥—ã."
    
    description = await vision_llm.extract_visual_info(
        media_url=media['url'],
        prompt=prompt
    )
    # –†–µ–∑—É–ª—å—Ç–∞—Ç: "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: –ª–æ–≥–æ—Ç–∏–ø –±—Ä–µ–Ω–¥–∞ XYZ, —Å—á–∞—Å—Ç–ª–∏–≤—ã–µ –ª—é–¥–∏ –≤ —Å–∏–Ω–µ–π –æ–¥–µ–∂–¥–µ, 
    #             —Ç–µ–∫—Å—Ç '–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è 2024', —è—Ä–∫–∏–µ —Ü–≤–µ—Ç–∞"
    
    vision_descriptions.append({
        'media_url': media['url'],
        'media_type': media['type'],  # image or video
        'description': description
    })
```

### –®–∞–≥ 2: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

```python
# –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
original_text = "\n\n".join([item['text'] for item in classified['text']])

# –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
combined_text = original_text

if vision_descriptions:
    combined_text += "\n\n[–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]:\n"
    for i, vd in enumerate(vision_descriptions, 1):
        combined_text += f"{i}. {vd['media_type'].upper()}: {vd['description']}\n"

# –ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:
# """
# –í—Å—Ç—Ä–µ—á–∞–π—Ç–µ –Ω–∞—à—É –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é!
# 
# [–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]:
# 1. IMAGE: –ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: –ª–æ–≥–æ—Ç–∏–ø –±—Ä–µ–Ω–¥–∞ XYZ, —Å—á–∞—Å—Ç–ª–∏–≤—ã–µ –ª—é–¥–∏ –≤ —Å–∏–Ω–µ–π –æ–¥–µ–∂–¥–µ, 
#           —Ç–µ–∫—Å—Ç '–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è 2024', —è—Ä–∫–∏–µ —Ü–≤–µ—Ç–∞
# """
```

### –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –û–î–ù–û–ô –º–æ–¥–µ–ª—å—é

```python
# –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å (DeepSeek) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
# –û–Ω–∞ –ø–æ–ª—É—á–∞–µ—Ç –ò —Ç–µ–∫—Å—Ç –ò –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏.
–£—á–∏—Ç—ã–≤–∞–π –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å, —Ç–∞–∫ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω).

–ö–û–ù–¢–ï–ù–¢:
{combined_text}

–û–ø—Ä–µ–¥–µ–ª–∏:
1. –û–±—â—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (positive/negative/neutral)
2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã
3. –£–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤
4. –°–≤—è–∑—å –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
5. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."""

result = await text_llm.analyze(
    combined_text=combined_text,
    prompt=prompt
)

# –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –ü–û–ù–ò–ú–ê–ï–¢ —Å–≤—è–∑—å:
# "Positive sentiment - –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è 
#  –≤–∏–∑—É–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å –ª–æ–≥–æ—Ç–∏–ø–æ–º –∏ —Ç–µ–∫—Å—Ç–æ–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"
```

## üîß –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–¥–µ

### –§–∞–π–ª: `app/services/ai/analyzer_v2.py`

```python
class AIAnalyzerV2:
    async def analyze_content(self, content, source):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
        
        # 1. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
        classified = ContentClassifier.classify_content(content)
        
        # 2. –ò–∑–≤–ª–µ—á—å –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å –º–µ–¥–∏–∞)
        vision_context = await self._extract_visual_context(
            classified['images'],
            classified['videos'],
            bot_scenario
        )
        
        # 3. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç + –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        combined_content = self._combine_text_and_vision(
            classified['text'],
            vision_context
        )
        
        # 4. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å—ë –≤–º–µ—Å—Ç–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é
        analysis_result = await self._analyze_combined_content(
            combined_content,
            bot_scenario,
            content_stats,
            platform_name,
            source
        )
        
        # 5. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return await self._save_analysis(
            analysis_result,
            source,
            topic_chain_id,
            parent_analysis_id
        )
    
    async def _extract_visual_context(
        self, 
        images: list, 
        videos: list,
        bot_scenario: BotScenario
    ) -> list[dict]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç.
        
        Returns:
            List of dicts: [
                {
                    'media_url': str,
                    'media_type': 'image' | 'video',
                    'description': str
                }
            ]
        """
        if not images and not videos:
            return []
        
        # –ü–æ–ª—É—á–∏—Ç—å Vision LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        vision_provider = await self._get_vision_llm_provider(bot_scenario)
        if not vision_provider:
            logger.warning("No vision LLM provider available")
            return []
        
        vision_client = LLMClientFactory.create(vision_provider)
        vision_descriptions = []
        
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for img in images[:10]:  # –õ–∏–º–∏—Ç –Ω–∞ –∫–æ–ª-–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            try:
                prompt = """–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ.
–£–∫–∞–∂–∏: –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã, –ª—é–¥–µ–π, —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å), —ç–º–æ—Ü–∏–∏, –±—Ä–µ–Ω–¥—ã, —Ü–≤–µ—Ç–∞.
–ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–µ–Ω, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
                
                description = await vision_client.analyze_image(
                    image_url=img['url'],
                    prompt=prompt
                )
                
                vision_descriptions.append({
                    'media_url': img['url'],
                    'media_type': 'image',
                    'description': description
                })
            except Exception as e:
                logger.error(f"Failed to analyze image {img['url']}: {e}")
        
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ)
        for vid in videos[:5]:  # –õ–∏–º–∏—Ç –Ω–∞ –∫–æ–ª-–≤–æ –≤–∏–¥–µ–æ
            try:
                prompt = """–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –≤–∏–¥–µ–æ.
–£–∫–∞–∂–∏: –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –ª—é–¥–µ–π, —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å), —Ç–µ–º–∞—Ç–∏–∫—É.
–ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–µ–Ω, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
                
                description = await vision_client.analyze_video(
                    video_url=vid['url'],
                    prompt=prompt
                )
                
                vision_descriptions.append({
                    'media_url': vid['url'],
                    'media_type': 'video',
                    'description': description
                })
            except Exception as e:
                logger.error(f"Failed to analyze video {vid['url']}: {e}")
        
        return vision_descriptions
    
    def _combine_text_and_vision(
        self,
        text_items: list,
        vision_context: list[dict]
    ) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏.
        
        Returns:
            Combined text ready for analysis
        """
        # –°–æ–±—Ä–∞—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        text_parts = []
        for item in text_items:
            if item.get('text'):
                text_parts.append(item['text'])
        
        combined = "\n\n".join(text_parts)
        
        # –î–æ–±–∞–≤–∏—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if vision_context:
            combined += "\n\n[–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]:\n"
            for i, vc in enumerate(vision_context, 1):
                media_type_label = "–ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï" if vc['media_type'] == 'image' else "–í–ò–î–ï–û"
                combined += f"{i}. {media_type_label}: {vc['description']}\n"
        
        return combined
    
    async def _analyze_combined_content(
        self,
        combined_text: str,
        bot_scenario: BotScenario,
        content_stats: dict,
        platform_name: str,
        source: Source
    ) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç–µ–∫—Å—Ç + –æ–ø–∏—Å–∞–Ω–∏—è –º–µ–¥–∏–∞).
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä DeepSeek), –∫–æ—Ç–æ—Ä–∞—è —Ç–µ–ø–µ—Ä—å
        –∏–º–µ–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–∞—è –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
        """
        # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é LLM
        text_provider = await self._get_text_llm_provider(bot_scenario)
        if not text_provider:
            raise ValueError("No text LLM provider available")
        
        text_client = LLMClientFactory.create(text_provider)
        
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ –≤–∫–ª—é—á–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        prompt = PromptBuilder.build_combined_analysis_prompt(
            combined_text=combined_text,
            content_stats=content_stats,
            platform_name=platform_name,
            analysis_types=bot_scenario.analysis_types if bot_scenario else []
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        result = await text_client.analyze(prompt)
        
        return {
            'analysis': result,
            'llm_model': text_provider.model_name,
            'has_visual_context': '[–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]' in combined_text,
            'combined_text_length': len(combined_text)
        }
    
    async def _get_vision_llm_provider(self, bot_scenario: BotScenario) -> Optional[LLMProvider]:
        """–ü–æ–ª—É—á–∏—Ç—å Vision LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä (–¥–ª—è image –∏–ª–∏ video)."""
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏—Ç—å image –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        if bot_scenario and bot_scenario.image_llm_provider_id:
            return await LLMProvider.objects.get(id=bot_scenario.image_llm_provider_id)
        
        # Fallback: –Ω–∞–π—Ç–∏ –ª—é–±–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Å image –∏–ª–∏ video capability
        providers = await LLMProvider.objects.filter(is_active=True)
        for provider in providers:
            if 'image' in provider.capabilities or 'video' in provider.capabilities:
                return provider
        
        return None
```

### –ù–æ–≤—ã–π —Ñ–∞–π–ª: `app/services/ai/prompts.py` (–¥–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥)

```python
@staticmethod
def build_combined_analysis_prompt(
    combined_text: str,
    content_stats: dict,
    platform_name: str,
    analysis_types: list[str]
) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ç–µ–∫—Å—Ç + –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ).
    """
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏ {platform_name}.

–í–ê–ñ–ù–û: –ö–æ–Ω—Ç–µ–Ω—Ç –≤–∫–ª—é—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å –ò –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –≤ —Ä–∞–∑–¥–µ–ª–µ [–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]).
–£—á–∏—Ç—ã–≤–∞–π –°–í–Ø–ó–¨ –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ.

–ö–û–ù–¢–ï–ù–¢ ({content_stats['total_items']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤):
{combined_text[:4000]}  # –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤

–ó–ê–î–ê–ß–ò –ê–ù–ê–õ–ò–ó–ê:
"""
    
    if 'sentiment' in analysis_types:
        prompt += """
1. –ê–ù–ê–õ–ò–ó –¢–û–ù–ê–õ–¨–ù–û–°–¢–ò:
   - –û–ø—Ä–µ–¥–µ–ª–∏ –æ–±—â—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (positive/negative/neutral/mixed)
   - –£—á–∏—Ç—ã–≤–∞–π –∫–∞–∫ —Ç–µ–∫—Å—Ç, —Ç–∞–∫ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
   - –û—Ü–µ–Ω–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
"""
    
    if 'topics' in analysis_types:
        prompt += """
2. –ê–ù–ê–õ–ò–ó –¢–ï–ú:
   - –û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
   - –£—á–∏—Ç—ã–≤–∞–π —Å–≤—è–∑—å —Ç–µ–∫—Å—Ç–∞ —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
   - –í—ã—è–≤–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
"""
    
    if 'brand_mentions' in analysis_types:
        prompt += """
3. –£–ü–û–ú–ò–ù–ê–ù–ò–Ø –ë–†–ï–ù–î–û–í:
   - –ù–∞–π–¥–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
   - –û–ø—Ä–µ–¥–µ–ª–∏ –≤–∏–¥–∏–º–æ—Å—Ç—å –±—Ä–µ–Ω–¥–æ–≤ –≤ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–Ω—Ç–µ (–ª–æ–≥–æ—Ç–∏–ø—ã, –ø—Ä–æ–¥—É–∫—Ç—ã)
   - –û—Ü–µ–Ω–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
"""
    
    prompt += """

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å –ø–æ–ª—è–º–∏:
{
  "overall_sentiment": "positive/negative/neutral/mixed",
  "sentiment_score": 0-100,
  "main_topics": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2"],
  "brand_mentions": [{"brand": "–Ω–∞–∑–≤–∞–Ω–∏–µ", "context": "–∫–æ–Ω—Ç–µ–∫—Å—Ç", "visual": true/false}],
  "text_visual_coherence": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
  "key_insights": ["–∏–Ω—Å–∞–π—Ç1", "–∏–Ω—Å–∞–π—Ç2"]
}
"""
    
    return prompt
```

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤

### –¢–µ–∫—É—â–∏–π –ø–æ–¥—Ö–æ–¥ (3 –∑–∞–ø—Ä–æ—Å–∞):

```
–ü–æ—Å—Ç: "–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è!" + –§–æ—Ç–æ –ª–æ–≥–æ—Ç–∏–ø–∞

–ó–∞–ø—Ä–æ—Å 1: DeepSeek (text only)
  Input: "–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è!"
  Output: "Positive, announcement"
  Cost: ~100 tokens √ó $0.0001 = $0.00001

–ó–∞–ø—Ä–æ—Å 2: GPT-4V (image only)
  Input: image + "–û–ø–∏—à–∏ —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ"
  Output: "Logo visible, blue colors"
  Cost: ~500 tokens √ó $0.01 = $0.005

–ó–∞–ø—Ä–æ—Å 3: DeepSeek (combine results)
  Input: "Combine: announcement + logo"
  Output: unified summary
  Cost: ~200 tokens √ó $0.0001 = $0.00002

–ò–¢–û–ì–û: $0.00503 (0.5 —Ü–µ–Ω—Ç–∞)
–ü–†–û–ë–õ–ï–ú–ê: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Ç–µ—Ä—è–Ω!
```

### –ù–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ (2 –∑–∞–ø—Ä–æ—Å–∞):

```
–ü–æ—Å—Ç: "–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è!" + –§–æ—Ç–æ –ª–æ–≥–æ—Ç–∏–ø–∞

–ó–∞–ø—Ä–æ—Å 1: GPT-4V (extract visual to text)
  Input: image + "–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏ —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ"
  Output: "–õ–æ–≥–æ—Ç–∏–ø –±—Ä–µ–Ω–¥–∞, —Å–∏–Ω–∏–µ —Ü–≤–µ—Ç–∞, —Ç–µ–∫—Å—Ç '2024'"
  Cost: ~300 tokens √ó $0.01 = $0.003

–ó–∞–ø—Ä–æ—Å 2: DeepSeek (analyze combined context)
  Input: "–ù–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è!\n[–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢]: –õ–æ–≥–æ—Ç–∏–ø –±—Ä–µ–Ω–¥–∞..."
  Output: "Positive sentiment, brand announcement with visual confirmation"
  Cost: ~250 tokens √ó $0.0001 = $0.000025

–ò–¢–û–ì–û: $0.003025 (0.3 —Ü–µ–Ω—Ç–∞)
–≠–ö–û–ù–û–ú–ò–Ø: 40% + –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω!
```

## ‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

1. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** üéØ
   - –¢–µ–∫—Å—Ç –∏ –º–µ–¥–∏–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –≤–º–µ—Å—Ç–µ
   - –ü–æ–Ω—è—Ç–Ω–∞ —Å–≤—è–∑—å –º–µ–∂–¥—É –Ω–∏–º–∏
   - –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑

2. **–≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤** üí∞
   - 2 –∑–∞–ø—Ä–æ—Å–∞ –≤–º–µ—Å—Ç–æ 3-4
   - ~40-70% —ç–∫–æ–Ω–æ–º–∏–∏
   - –ú–µ–Ω—å—à–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤

3. **–ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** üèóÔ∏è
   - –õ–∏–Ω–µ–π–Ω—ã–π flow: Vision ‚Üí Combine ‚Üí Analyze
   - –õ–µ–≥—á–µ –æ—Ç–ª–∞–¥–∫–∞
   - –ú–µ–Ω—å—à–µ —Ç–æ—á–µ–∫ –æ—Ç–∫–∞–∑–∞

4. **–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ** ‚≠ê
   - –ú–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
   - –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–≤—è–∑–∏
   - –ë–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑

## üìù Checklist –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- [ ] –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_extract_visual_context()` –≤ `AIAnalyzerV2`
- [ ] –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_combine_text_and_vision()` –≤ `AIAnalyzerV2`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_analyze_combined_content()` –≤ `AIAnalyzerV2`
- [ ] –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_get_vision_llm_provider()` –≤ `AIAnalyzerV2`
- [ ] –î–æ–±–∞–≤–∏—Ç—å `build_combined_analysis_prompt()` –≤ `PromptBuilder`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `LLMClient` –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ `analyze_image()` –∏ `analyze_video()`
- [ ] –î–æ–±–∞–≤–∏—Ç—å –ª–∏–º–∏—Ç—ã –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –º–µ–¥–∏–∞ (–∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ—Ä–∞—Å—Ö–æ–¥–∞)
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø–æ—Å—Ç–∞–º–∏
- [ ] –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ç–∞—Ä–æ–π –∏ –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–∏
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

## üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# –¢–µ—Å—Ç–æ–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
test_content = [
    {
        'text': '–í—Å—Ç—Ä–µ—á–∞–π—Ç–µ –Ω–∞—à—É –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é!',
        'images': [
            {'url': 'https://example.com/logo.jpg'}
        ]
    }
]

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑
result = await AIAnalyzerV2().analyze_content(
    content=test_content,
    source=test_source
)

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ:
# 1. Vision –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ —Ç–µ–∫—Å—Ç—É
# 2. –ê–Ω–∞–ª–∏–∑ —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
# 3. –¢–æ–∫–µ–Ω—ã —Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω—ã
# 4. –ö–∞—á–µ—Å—Ç–≤–æ —É–ª—É—á—à–∏–ª–æ—Å—å
```

## üìå –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç

**HIGH** - –ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤

## üïê –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏

~4-6 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã:
- 2 —á–∞—Å–∞: —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ `AIAnalyzerV2`
- 1 —á–∞—Å: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
- 1 —á–∞—Å: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ `LLMClient`
- 1-2 —á–∞—Å–∞: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

- `app/services/ai/analyzer_v2.py` (–æ—Å–Ω–æ–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
- `app/services/ai/prompts.py` (–Ω–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã)
- `app/services/ai/llm_client.py` (–º–µ—Ç–æ–¥—ã –¥–ª—è vision)
- `app/services/ai/content_classifier.py` (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
